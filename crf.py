# -*- coding: utf-8 -*-
"""CRF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1agq4MphYY0XY_DYOFZRCW9rZ6IQBJgR9
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.style.use('ggplot')

pip install -U 'scikit-learn<0.24'

from itertools import chain

import nltk
import sklearn
import scipy.stats
from sklearn.metrics import make_scorer
from sklearn.model_selection import cross_val_score
from nltk.tokenize import word_tokenize

import sklearn_crfsuite
from sklearn_crfsuite import scorers
from sklearn_crfsuite import metrics

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

XTr=['Google wants a backend developer with good coding skills','There is a position open for machine learning engineer, Meta is looking for people with machine learning background']
XVal=['Amazon is looking for DevOps engineer']
org_b={'google':'C','amazon':'C','meta':'C','microsoft':'C','qualcomm':'C'}
skills_b={'coding':'S','machine':'S','learning':'S'}
jobs_b={'backend':'J','developer':'J','engineer':'J','manager':'J','devops':'J'}

def make(X,org_b,skills_b,jobs_b):
  big=[]
  for sentence in X:
    token=word_tokenize(sentence)
    small=[]
    token_t=nltk.pos_tag(token)
    for f,s in token_t:
      tag='O'
      if f.lower() in org_b:
        tag=org_b[f.lower()]
      if f.lower() in skills_b:
        tag=skills_b[f.lower()]
      if f.lower() in jobs_b:
        tag=jobs_b[f.lower()]
      small.append((f,s,tag))
    big.append(small)
  return big
XTr_=make(XTr,org_b,skills_b,jobs_b)
XVal_=make(XVal,org_b,skills_b,jobs_b)

def getfeatures(dat,i):
  word=dat[i][0]
  postag=dat[i][1]
  features = {
        'bias': 1.0,
        'word.lower()': word.lower(),
        'word[-3:]': word[-3:],
        'word[-2:]': word[-2:],
        'word.isupper()': word.isupper(),
        'word.istitle()': word.istitle(),
        'word.isdigit()': word.isdigit(),
        'postag': postag,
        'postag[:2]': postag[:2],
  }
  if i>0:
    word=dat[i-1][0]
    postag=dat[i-1][1]
    features.update({
        '-1:word.lower()': word.lower(),    
        '-1:word.isupper()': word.isupper(),
        '-1:word.istitle()': word.istitle(),
        '-1:postag': postag,
        '-1:postag[:2]': postag[:2]
    })
  else:
    features['BOS']=True
  if i+1<len(dat):
    word=dat[i+1][0]
    postag=dat[i+1][1]
    features.update({
        '+1:word.lower()': word.lower(),    
        '+1:word.isupper()': word.isupper(),
        '+1:word.istitle()': word.istitle(),
        '+1:postag': postag,
        '+1:postag[:2]': postag[:2]
    })
  else:
    features['EOS']=True
  return features

def f2features(dat):
    return [getfeatures(dat, i) for i in range(len(dat))]

def f2labels(dat):
    return [label for token, postag, label in dat]

def f2tokens(dat):
    return [token for token, postag, label in dat]

XTr__=[f2features(x) for x in XTr_]
YTr__=[f2labels(x) for x in XTr_]

XVal__=[f2features(x) for x in XVal_]
YVal__=[f2labels(x) for x in XVal_]

crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=0.1,
    c2=0.1,
    max_iterations=100,
    all_possible_transitions=True
)

crf.fit(XTr__, YTr__)

labls=crf.classes_
labls.remove('O')

y_pred = crf.predict(XVal__)
metrics.flat_f1_score(YVal__, y_pred,average='weighted', labels=labls)

print(metrics.flat_classification_report(YVal__, y_pred,digits=3))

y_pred