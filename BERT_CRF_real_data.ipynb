{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnqByJL5p7Cy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import keras \n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import LSTM,Bidirectional,Dense,Input,Embedding,TimeDistributed\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive,files\n",
        "drive.mount(\"/content/drive\")\n",
        "dataM='/content/drive/My Drive/Colab Notebooks/MODELS/'\n",
        "filepath = dataM+'BERT_CRF.ml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j61YwHzBmzVS",
        "outputId": "7f1ee00f-0713-4b16-adf4-7fddf3b8b83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrumAEPItxDE",
        "outputId": "17455a7d-0b3d-4ffc-ed39-c3e0c0c88183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.27.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (22.11.23)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_8exmkqms6B",
        "outputId": "a250cf3a-8536-40c1-f08b-094ca08540b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F7UY69onOnp",
        "outputId": "55d39dab-d885-4578-e413-d030e47f6231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf2crf in /usr/local/lib/python3.7/dist-packages (0.1.33)\n",
            "Requirement already satisfied: tensorflow-addons>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (0.18.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.27.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (4.1.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.19.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (22.11.23)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->tf2crf) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1.0->tf2crf) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.1.0->tf2crf) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.1.0->tf2crf) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tf2crf import CRF \n",
        "from tf2crf import ModelWithCRFLoss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6mw5TP5nSsw",
        "outputId": "557359ef-0ea8-4403-930c-a1b2e5c3c73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data \n",
        "import pandas as pd\n",
        "import json\n",
        "path_to_json = '/content/drive/My Drive/Colab Notebooks/data/job_20k.json'\n",
        "df  = pd.read_json(path_to_json,lines=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "y9VVaNOzLsId",
        "outputId": "4e8bf3ac-973d-48ba-da85-8d8807b8d0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        clean_descrition  \\\n",
              "0      A technology services client of ours is lookin...   \n",
              "1      Job Title :Java Sr developerLocation: RemoteLo...   \n",
              "2      Mandatory Skills: Strong in Oracle database 19...   \n",
              "3      Associate Scientist Thousand Oaks, CADescripti...   \n",
              "4      Growing fintech company looking for Mid Level,...   \n",
              "...                                                  ...   \n",
              "19901  Tranzeal is an industry leading global Busines...   \n",
              "19902  About us: As a Fortune 50 company with more th...   \n",
              "19903  Ability to provide effective independent techn...   \n",
              "19904  Requirements:5 years of experience as a . Net ...   \n",
              "19905  We are currently seeking a Portfolio Valuation...   \n",
              "\n",
              "                         organization_list  \\\n",
              "0       [Swift, Strategic, Solutions, Inc]   \n",
              "1      [AQUA, Information, Systems,, Inc.]   \n",
              "2               [Softnet, Consulting, Inc]   \n",
              "3                          [Apex, Systems]   \n",
              "4                                  [Jobot]   \n",
              "...                                    ...   \n",
              "19901                    [Tranzeal,, Inc.]   \n",
              "19902                [Target, Corporation]   \n",
              "19903                  [InfoVision,, Inc.]   \n",
              "19904                [Resourcesoft,, Inc.]   \n",
              "19905                [The, Midtown, Group]   \n",
              "\n",
              "                                              skill_list  \\\n",
              "0      [NoSQL, Teradata, Netezza, Cosmos, DB, JSON, A...   \n",
              "1                                      [Java, JEE, J2EE]   \n",
              "2      [Oracle, database, 19c, Advanced, PL/SQL, prog...   \n",
              "3           [Biochemistry, Biology, Analytical, Systems]   \n",
              "4      [Developer, JavaScript, SQL, ASP, HTML, Archit...   \n",
              "...                                                  ...   \n",
              "19901  [Experience, with, mobile, software, developme...   \n",
              "19902                                         [Engineer]   \n",
              "19903     [Informatica, or, Azure, Cloud, MDM, programs]   \n",
              "19904           [.net, sitecore, cms, c#, web, services]   \n",
              "19905  [energy, subsectors, valuing, portfolio, inves...   \n",
              "\n",
              "                                          job_title_list  \n",
              "0                                    [Bigdata, Engineer]  \n",
              "1                                      [Java, developer]  \n",
              "2                      [Oracle, PL/SQL, Lead, Architect]  \n",
              "3                                 [Associate, Scientist]  \n",
              "4                                   [Software, Engineer]  \n",
              "...                                                  ...  \n",
              "19901                                   [iOS, Developer]  \n",
              "19902                                  [Engineer, -, US]  \n",
              "19903                                   [MDM, Architect]  \n",
              "19904                             [Sitecore, Consultant]  \n",
              "19905  [Portfolio, Valuation, Assistant, Vice, Presid...  \n",
              "\n",
              "[19906 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84ba1dbb-d1cd-4cbf-98c3-cb31351bb7f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_descrition</th>\n",
              "      <th>organization_list</th>\n",
              "      <th>skill_list</th>\n",
              "      <th>job_title_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A technology services client of ours is lookin...</td>\n",
              "      <td>[Swift, Strategic, Solutions, Inc]</td>\n",
              "      <td>[NoSQL, Teradata, Netezza, Cosmos, DB, JSON, A...</td>\n",
              "      <td>[Bigdata, Engineer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Job Title :Java Sr developerLocation: RemoteLo...</td>\n",
              "      <td>[AQUA, Information, Systems,, Inc.]</td>\n",
              "      <td>[Java, JEE, J2EE]</td>\n",
              "      <td>[Java, developer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mandatory Skills: Strong in Oracle database 19...</td>\n",
              "      <td>[Softnet, Consulting, Inc]</td>\n",
              "      <td>[Oracle, database, 19c, Advanced, PL/SQL, prog...</td>\n",
              "      <td>[Oracle, PL/SQL, Lead, Architect]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Associate Scientist Thousand Oaks, CADescripti...</td>\n",
              "      <td>[Apex, Systems]</td>\n",
              "      <td>[Biochemistry, Biology, Analytical, Systems]</td>\n",
              "      <td>[Associate, Scientist]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Growing fintech company looking for Mid Level,...</td>\n",
              "      <td>[Jobot]</td>\n",
              "      <td>[Developer, JavaScript, SQL, ASP, HTML, Archit...</td>\n",
              "      <td>[Software, Engineer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19901</th>\n",
              "      <td>Tranzeal is an industry leading global Busines...</td>\n",
              "      <td>[Tranzeal,, Inc.]</td>\n",
              "      <td>[Experience, with, mobile, software, developme...</td>\n",
              "      <td>[iOS, Developer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19902</th>\n",
              "      <td>About us: As a Fortune 50 company with more th...</td>\n",
              "      <td>[Target, Corporation]</td>\n",
              "      <td>[Engineer]</td>\n",
              "      <td>[Engineer, -, US]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19903</th>\n",
              "      <td>Ability to provide effective independent techn...</td>\n",
              "      <td>[InfoVision,, Inc.]</td>\n",
              "      <td>[Informatica, or, Azure, Cloud, MDM, programs]</td>\n",
              "      <td>[MDM, Architect]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19904</th>\n",
              "      <td>Requirements:5 years of experience as a . Net ...</td>\n",
              "      <td>[Resourcesoft,, Inc.]</td>\n",
              "      <td>[.net, sitecore, cms, c#, web, services]</td>\n",
              "      <td>[Sitecore, Consultant]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19905</th>\n",
              "      <td>We are currently seeking a Portfolio Valuation...</td>\n",
              "      <td>[The, Midtown, Group]</td>\n",
              "      <td>[energy, subsectors, valuing, portfolio, inves...</td>\n",
              "      <td>[Portfolio, Valuation, Assistant, Vice, Presid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19906 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84ba1dbb-d1cd-4cbf-98c3-cb31351bb7f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84ba1dbb-d1cd-4cbf-98c3-cb31351bb7f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84ba1dbb-d1cd-4cbf-98c3-cb31351bb7f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_descrition'] = df['clean_descrition'].str.replace(r'[^\\w\\s]+', ' ')\n",
        "df['clean_descrition'] = df['clean_descrition'].apply(lambda x: ' '.join(x.split()[:128]))\n",
        "df['clean_descrition'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "XioBIEK7Lrwd",
        "outputId": "1221f9a2-46e5-4416-acf8-955e3c66a839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Job Title Java Sr developerLocation RemoteLong TermSkills java jeShould have good understanding on the change management role and had depth knowledge on the change advisory board process CAB Good knowledge on the incident management Problem management Change Management Should have involved in the 3L level of activities i e root cause analysis environment analysis understanding the application architecture infrastructure architecture The resource should have very good understanding on the SDLC process Very good knowledge on the Java J2EE and have hands on experience in understanding the architecture of heterogeneous application Good communication skills and team handling abilities Should have worked'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jobs = list(df.clean_descrition)\n",
        "def convert_to_list_then_dict(df_column= None, key_value=str):\n",
        "    value_list = list(df_column)\n",
        "    _ = list(set([item for value_list in value_list for item in value_list]))\n",
        "    return dict.fromkeys(_, key_value)\n",
        "\n",
        "org = convert_to_list_then_dict(df_column=df.organization_list, key_value='C')\n",
        "skill = convert_to_list_then_dict(df_column=df.skill_list, key_value='S')\n",
        "job = convert_to_list_then_dict(df_column=df.job_title_list, key_value='J')    "
      ],
      "metadata": {
        "id": "E-RwkGQuL0yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check text length\n",
        "# for i in jobs:\n",
        "#   if (len(i.split())) < 128:\n",
        "#     jobs.remove(i)"
      ],
      "metadata": {
        "id": "Ix63mNkeVg0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in jobs:\n",
        "#   if len(i.split()) !=128:\n",
        "#     print(len(i.split()))"
      ],
      "metadata": {
        "id": "Q0PNp9SrWGOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split\n",
        "# XTr= jobs[:1500]\n",
        "# XVal= jobs[1500:2000]\n",
        "XTr= jobs[:151]\n",
        "XVal= jobs[150:200]\n",
        "org_b = org\n",
        "skills_b = skill\n",
        "jobs_b = job"
      ],
      "metadata": {
        "id": "WdE5FpZNL3dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XTr=['Google wants a backend developer with good coding skills','There is a position open for machine learning engineer, Meta is looking for people with machine learning background']\n",
        "# XVal=['Amazon is looking for DevOps engineer']\n",
        "# org_b={'google':'C','amazon':'C','meta':'C','microsoft':'C','qualcomm':'C'}\n",
        "# skills_b={'coding':'S','machine':'S','learning':'S'}\n",
        "# jobs_b={'backend':'J','developer':'J','engineer':'J','manager':'J','devops':'J'}\n",
        "\n",
        "def make(X,org_b,skills_b,jobs_b):\n",
        "  big=[]\n",
        "  for sentence in X:\n",
        "    token=word_tokenize(sentence)\n",
        "    small=[]\n",
        "    token_t=nltk.pos_tag(token)\n",
        "    for f,s in token_t:\n",
        "      tag='O'\n",
        "      if f.lower() in org_b:\n",
        "        tag=org_b[f.lower()]\n",
        "      if f.lower() in skills_b:\n",
        "        tag=skills_b[f.lower()]\n",
        "      if f.lower() in jobs_b:\n",
        "        tag=jobs_b[f.lower()]\n",
        "      small.append((f,s,tag))\n",
        "    big.append(small)\n",
        "  return big\n",
        "  \n",
        "XTr_=make(XTr,org_b,skills_b,jobs_b)\n",
        "XVal_=make(XVal,org_b,skills_b,jobs_b)"
      ],
      "metadata": {
        "id": "7AXy_swXiI0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msgLen=128\n",
        "\n",
        "def fixMsg(X):\n",
        "  global msgLen\n",
        "  Xc=[]\n",
        "  for i in range(len(X)):\n",
        "    if len(X[i])<msgLen:\n",
        "      while len(X[i])<msgLen:\n",
        "        X[i].append(('UNK','UNK','UNK'))\n",
        "    elif len(X[i])>msgLen:\n",
        "      temp=X[i]\n",
        "      del X[i]\n",
        "      lb=0;chunk=msgLen\n",
        "      while lb<len(temp):\n",
        "        split=[]\n",
        "        for j in range(lb,lb+chunk):\n",
        "          if j<len(temp):\n",
        "            split.append(temp[j])\n",
        "          else:\n",
        "            split.append(('UNK','UNK','UNK'))\n",
        "        X.append(split)\n",
        "        print(X)\n",
        "        lb+=chunk\n",
        "  return X \n",
        "\n",
        "XTr_t=fixMsg(XTr_)\n",
        "XVal_t=fixMsg(XVal_)"
      ],
      "metadata": {
        "id": "Y_-Ff7j4K-8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## remove\n",
        "# for x in XTr_t:\n",
        "#   if len(x)!=msgLen:\n",
        "#     # print((x))\n",
        "#     # print(len(x))\n",
        "#     XTr_t.remove(x)"
      ],
      "metadata": {
        "id": "wIuko36zOqMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in XTr_t:\n",
        "  # print(len(x))\n",
        "  assert(len(x)==msgLen)\n",
        "# print(XTr_t)\n",
        "for x in XVal_t:\n",
        "  # print(len(x))\n",
        "  assert(len(x)==msgLen)\n",
        "# print(XVal_t)"
      ],
      "metadata": {
        "id": "vyWah1_jOg4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_={}\n",
        "dict_1={}\n",
        "token=1;token1=0\n",
        "for x in XTr_t:\n",
        "  for a,b,c in x:\n",
        "    if a not in dict_:\n",
        "      dict_[a]=token\n",
        "      token=token+1\n",
        "    if c not in dict_1:\n",
        "      if c=='K':\n",
        "        print(a,b,c)\n",
        "      dict_1[c]=token1\n",
        "      token1=token1+1\n",
        "for x in XVal_t:\n",
        "  for a,b,c in x:\n",
        "    if a not in dict_:\n",
        "      dict_[a]=token\n",
        "      token=token+1\n",
        "    if c not in dict_1:\n",
        "      dict_1[c]=token1\n",
        "      token1=token1+1\n",
        "print('No of tokens words[{}] labels[{}]'.format(token,token1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkBnDQtzK6tv",
        "outputId": "12c275ec-31e8-42ef-ee59-6d57e84462ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of tokens words[4464] labels[5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XTr_fin=np.array(XTr)\n",
        "XVal_fin=np.array(XVal)\n",
        "\n",
        "yTr=np.array([[dict_1[element[2]] for element in sentence] for sentence in XTr_t])\n",
        "yVal=np.array([[dict_1[element[2]] for element in sentence] for sentence in XVal_t])"
      ],
      "metadata": {
        "id": "P_y_gHDnAhgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_text as text\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\")"
      ],
      "metadata": {
        "id": "_B_hNyzybO5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed = preprocessor(XTr_fin)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjTRD0xJQojC",
        "outputId": "75a8c208-7b78-4b18-9e27-300b54fad91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_type_ids', 'input_word_ids', 'input_mask']\n",
            "Shape      : (151, 128)\n",
            "Word Ids   : [  101   138  2815  1826  7230  1104 17079  1110  1702  1370  2562 27922]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4\n",
        "# https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
        "\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4', trainable=False)"
      ],
      "metadata": {
        "id": "g2u-j7-WbQuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=Input(shape=(), dtype=tf.string)\n",
        "model0=preprocessor(input)\n",
        "seq_op=bert_layer(model0)['sequence_output']\n",
        "model0=Model(input,seq_op)\n",
        "model0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J936HqZHa09s",
        "outputId": "774c09de-b241-4242-848a-6cc50352dbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_16 (KerasLayer)    {'input_type_ids':   0           ['input_17[0][0]']               \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_17 (KerasLayer)    {'encoder_outputs':  108310273   ['keras_layer_16[0][0]',         \n",
            "                                 [(None, 128, 768),               'keras_layer_16[0][1]',         \n",
            "                                 (None, 128, 768),                'keras_layer_16[0][2]']         \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,310,273\n",
            "Trainable params: 0\n",
            "Non-trainable params: 108,310,273\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XTr_fin=model0.predict(XTr_fin)\n",
        "XVal_fin=model0.predict(XVal_fin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEj0r4mYblFo",
        "outputId": "6515d393-f764-42a4-d01e-9042ce0828c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 48s 9s/step\n",
            "2/2 [==============================] - 15s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(XTr_fin.shape,XVal_fin.shape,type(XTr_fin),type(XVal_fin))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd8vY1oMbsnX",
        "outputId": "b0998a5e-dbe3-443b-a3d5-ccbd66c28844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 128, 768) (50, 128, 768) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yTr.shape,yVal.shape,type(yTr),type(yVal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi0549Vzdzq1",
        "outputId": "a1e12e7e-9ec3-4c74-cee8-f2a6e1c921c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(152, 128) (50, 128) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=Input(shape=(XTr_fin.shape[1],XTr_fin.shape[2]))\n",
        "output=CRF(units=token1)(input)\n",
        "mo=Model(input,output)\n",
        "mo.summary()\n",
        "\n",
        "model1=ModelWithCRFLoss(mo,sparse_target=True)\n",
        "model1.compile(optimizer ='rmsprop')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZoGx_5ScEFq",
        "outputId": "d6b1f64c-4981-4b86-fdba-67068dc3ceb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 128, 768)]        0         \n",
            "                                                                 \n",
            " crf_8 (CRF)                 ((None, 128),             3870      \n",
            "                              (None, 128, 5),                    \n",
            "                              (None,),                           \n",
            "                              (5, 5))                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,870\n",
            "Trainable params: 3,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(np.array(XTr_fin),np.array(yTr),epochs=10,validation_data=[XVal_fin,yVal],batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "HPQRrIdGdhj7",
        "outputId": "55c6e86c-2ddf-47c8-b932-04421eebbc33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-190-02f264d14008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTr_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXVal_fin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myVal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1846\u001b[0m             )\n\u001b[1;32m   1847\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 151\n  y sizes: 152\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
        "plt.plot(history.history['val_loss_val'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('Epochs ->')\n",
        "plt.ylabel('Losses ->')\n",
        "plt.title('Losses v/s epochs.')\n",
        "plt.legend(['Val Loss','Train Loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6F4g0N5hgehe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_1R={}\n",
        "for k,v in dict_1.items():\n",
        "  dict_1R[v]=k"
      ],
      "metadata": {
        "id": "bY_MysV-guuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_=model1.predict(XVal_fin)\n",
        "i=0 # i-th example from val dataset.\n",
        "cnt=0\n",
        "print()\n",
        "for x in XVal_[0]:\n",
        "  print('{} {}'.format(x[0],dict_1R[labels_[i][cnt]]))\n",
        "  cnt+=1\n",
        "  if cnt>10:\n",
        "    break"
      ],
      "metadata": {
        "id": "Ql-tJynlgwLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_1"
      ],
      "metadata": {
        "id": "E9gE22cohHqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "metadata": {
        "id": "hBet4AARhQf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "def labelIt(yVal):\n",
        "  yVal_lis=[]\n",
        "  for y1 in yVal:\n",
        "    temp=[]\n",
        "    for y2 in y1:\n",
        "      temp.append(dict_1R[y2])\n",
        "    yVal_lis.append(temp)\n",
        "  return yVal_lis \n",
        "\n",
        "yVal_=labelIt(yVal)\n",
        "yPred_=labelIt(labels_)\n",
        "labls=['C','J','S','O','UNK']\n",
        "metrics.flat_f1_score(yVal_,yPred_,average='weighted',labels=labls)"
      ],
      "metadata": {
        "id": "SCEkHYsohUfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U 'scikit-learn<0.24'"
      ],
      "metadata": {
        "id": "1NJ6RBduijLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.flat_classification_report(yVal_,yPred_,labels=labls,digits=3))"
      ],
      "metadata": {
        "id": "2He4FsGYhXea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}