{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jYjjz0EnvJx0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U 'scikit-learn<0.24'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyosdHZtzU3r",
        "outputId": "2ab96389-a44b-4033-c4c7-e0df20ab4ebd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.7.3)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "metadata": {
        "id": "Wemq019sT3Pe",
        "outputId": "d1135cc3-f45a-4813-9533-c55f981b9451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.64.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "metadata": {
        "id": "bicdDftfvYHA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtcYIL2N7cgb",
        "outputId": "4b4509de-e319-47d9-a760-ccdbb9b36a33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XTr=['Google wants a backend developer with good coding skills','There is a position open for machine learning engineer, Meta is looking for people with machine learning background']\n",
        "XVal=['Amazon is looking for DevOps engineer']\n",
        "org_b={'google':'C','amazon':'C','meta':'C','microsoft':'C','qualcomm':'C'}\n",
        "skills_b={'coding':'S','machine':'S','learning':'S'}\n",
        "jobs_b={'backend':'J','developer':'J','engineer':'J','manager':'J','devops':'J'}\n",
        "\n",
        "def make(X,org_b,skills_b,jobs_b):\n",
        "  big=[]\n",
        "  for sentence in X:\n",
        "    token=word_tokenize(sentence)\n",
        "    small=[]\n",
        "    token_t=nltk.pos_tag(token)\n",
        "    for f,s in token_t:\n",
        "      tag='O'\n",
        "      if f.lower() in org_b:\n",
        "        tag=org_b[f.lower()]\n",
        "      if f.lower() in skills_b:\n",
        "        tag=skills_b[f.lower()]\n",
        "      if f.lower() in jobs_b:\n",
        "        tag=jobs_b[f.lower()]\n",
        "      small.append((f,s,tag))\n",
        "    big.append(small)\n",
        "  return big\n",
        "XTr_=make(XTr,org_b,skills_b,jobs_b)\n",
        "XVal_=make(XVal,org_b,skills_b,jobs_b)"
      ],
      "metadata": {
        "id": "zPBgJgpB0_5u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getfeatures(dat,i):\n",
        "  word=dat[i][0]\n",
        "  postag=dat[i][1]\n",
        "  features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "  }\n",
        "  if i>0:\n",
        "    word=dat[i-1][0]\n",
        "    postag=dat[i-1][1]\n",
        "    features.update({\n",
        "        '-1:word.lower()': word.lower(),    \n",
        "        '-1:word.isupper()': word.isupper(),\n",
        "        '-1:word.istitle()': word.istitle(),\n",
        "        '-1:postag': postag,\n",
        "        '-1:postag[:2]': postag[:2]\n",
        "    })\n",
        "  else:\n",
        "    features['BOS']=True\n",
        "  if i+1<len(dat):\n",
        "    word=dat[i+1][0]\n",
        "    postag=dat[i+1][1]\n",
        "    features.update({\n",
        "        '+1:word.lower()': word.lower(),    \n",
        "        '+1:word.isupper()': word.isupper(),\n",
        "        '+1:word.istitle()': word.istitle(),\n",
        "        '+1:postag': postag,\n",
        "        '+1:postag[:2]': postag[:2]\n",
        "    })\n",
        "  else:\n",
        "    features['EOS']=True\n",
        "  return features"
      ],
      "metadata": {
        "id": "6K4y12u61GL9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f2features(dat):\n",
        "    return [getfeatures(dat, i) for i in range(len(dat))]\n",
        "\n",
        "def f2labels(dat):\n",
        "    return [label for token, postag, label in dat]\n",
        "\n",
        "def f2tokens(dat):\n",
        "    return [token for token, postag, label in dat]"
      ],
      "metadata": {
        "id": "tLAwsHrSJGsr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XTr__=[f2features(x) for x in XTr_]\n",
        "YTr__=[f2labels(x) for x in XTr_]\n",
        "\n",
        "XVal__=[f2features(x) for x in XVal_]\n",
        "YVal__=[f2labels(x) for x in XVal_]"
      ],
      "metadata": {
        "id": "gelVnCDhaBOH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")"
      ],
      "metadata": {
        "id": "DWCD0bB9bMh5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crf.fit(XTr__, YTr__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8VzhF27dbZA",
        "outputId": "b72490e9-91b1-45be-9942-fd9a840d8a06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    keep_tempfiles=None, max_iterations=100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labls=crf.classes_\n",
        "labls.remove('O')"
      ],
      "metadata": {
        "id": "4DiSfVAffcpy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = crf.predict(XVal__)\n",
        "metrics.flat_f1_score(YVal__, y_pred,average='weighted', labels=labls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMwVW9q0d7kF",
        "outputId": "c064634f-0523-49e2-8a06-243abe50e81a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.flat_classification_report(YVal__, y_pred,digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltHoopW9fqjS",
        "outputId": "04332f10-7905-4905-9d11-7306617bf1dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C      1.000     1.000     1.000         1\n",
            "           J      0.000     0.000     0.000         2\n",
            "           O      0.600     1.000     0.750         3\n",
            "\n",
            "    accuracy                          0.667         6\n",
            "   macro avg      0.533     0.667     0.583         6\n",
            "weighted avg      0.467     0.667     0.542         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_H0d0929tC0",
        "outputId": "1ae116ec-b3b4-4c62-889d-c26ccabdc41c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['C', 'O', 'O', 'O', 'O', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xLC9WaCf9ux6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}